{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8375c7bb-678e-42d0-a686-6f2776f87325",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92bb4c7-407a-4768-a6ea-3b3cbc60bb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Pkg\n",
    "\n",
    "using Flux, MLDataPattern, Mill, JsonGrinder, JSON, Statistics, IterTools, StatsBase, ThreadTools\n",
    "using JsonGrinder: suggestextractor, ExtractDict\n",
    "using Mill: reflectinmodel\n",
    "using CSV, DataFrames\n",
    "using Random\n",
    "using Dates\n",
    "using Plots\n",
    "using Printf\n",
    "\n",
    "#using Zygote, MLDataPattern\n",
    "\n",
    "#ENV[\"PYTHON\"]=\"C:\\\\Users\\\\aleca\\\\anaconda3\\\\python.exe\"\n",
    "#Pkg.build(\"PyCall\")\n",
    "#using ScikitLearn, PyCall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563cc044-d8c6-44c9-8a23-b7b94b57edc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aba5cf9-66f2-4b5b-ad7c-7091a1327005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THREADS = Threads.nthreads() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c339ce-1541-4dde-99bf-f63c64c7346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_REDUCED_REPORTS = \"../Avast/public_small_reports/\"\n",
    "#PATH_TO_LABELS = \"../Avast/subset_10.csv\" ;\n",
    "#PATH_TO_LABELS = \"../Avast/subset_50.csv\" ;\n",
    "PATH_TO_LABELS = \"../Avast/subset_100.csv\" ;\n",
    "#PATH_TO_LABELS = \"../Avast/public_labels.csv\" ;#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05add69-5ac8-4f85-aff3-c4e71db6ed14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_labels=CSV.read(PATH_TO_LABELS,DataFrame);\n",
    "targets=df_labels.classification_family;\n",
    "labels=Set(df_labels.classification_family);\n",
    "n_classes=length(labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e20ab734-3cea-4263-a77a-53df8da504a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N samples: 1000\n",
      "N classes: 10\n"
     ]
    }
   ],
   "source": [
    "jsons = tmap(df_labels.sha256) do s\n",
    "    try \n",
    "        x=open(JSON.parse, \"$(PATH_TO_REDUCED_REPORTS)$(s).json\")\n",
    "        delete!(x,\"static\") # Take only the behavioral info\n",
    "        #delete!(x,\"behavior\") # Take only the static info\n",
    "    catch e\n",
    "        @error \"Error when processing sha $s: $e\"\n",
    "    end\n",
    "end ;\n",
    "\n",
    "n_samples=length(jsons)\n",
    "println(\"N samples: $(n_samples)\")\n",
    "println(\"N classes: $(n_classes)\")\n",
    "    \n",
    "@assert size(jsons, 1) == length(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046ade2c-982e-48a2-9f6f-2c8c0b501a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 817\n",
      "Test size: 183\n"
     ]
    }
   ],
   "source": [
    "timesplit = Date(2019,8,1)\n",
    "train_indexes = findall(i -> df_labels.date[i] < timesplit, 1:n_samples)\n",
    "test_indexes = [setdiff(Set(1:n_samples), Set(train_indexes))...] ;\n",
    "\n",
    "train_size = length(train_indexes)\n",
    "test_size = length(test_indexes)\n",
    "\n",
    "println(\"Train size: $(train_size)\")\n",
    "println(\"Test size: $(test_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a97495-e89c-4f22-8b0f-4c8d114a63ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define scheme and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca08e2bd-66c8-4a8e-a0e0-aa39420c9817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[Dict]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m  ╰── behavior: \u001b[39m\u001b[31m[Dict]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m  ╰── summary: \u001b[39m\u001b[32m[Dict]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├─────── delete_files: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 3342 unique values\u001b[90m  # updated = 4046\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├──────── delete_keys: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 22 unique values\u001b[90m  # updated = 116\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├─────────────── keys: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 10000 unique values\u001b[90m  # updated = 260546\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├──────────── mutexes: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 1206 unique values\u001b[90m  # updated = 2816\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├── executed_commands: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 1233 unique values\u001b[90m  # updated = 2333\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├─── started_services: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 4 unique values\u001b[90m  # updated = 74\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├───────── write_keys: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 1239 unique values\u001b[90m  # updated = 6480\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├────────────── files: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 10000 unique values\u001b[90m  # updated = 116567\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├─── created_services: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 2 unique values\u001b[90m  # updated = 2\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├────────── read_keys: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 10000 unique values\u001b[90m  # updated = 155180\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├──────── write_files: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 3822 unique values\u001b[90m  # updated = 4966\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ├────── resolved_apis: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  │                      \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 4367 unique values\u001b[90m  # updated = 155733\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m  ╰───────── read_files: \u001b[39m\u001b[33m[List]\u001b[39m\u001b[90m  # updated = 817\u001b[39m\n",
      "\u001b[34m                \u001b[39m\u001b[31m               \u001b[39m\u001b[32m                         \u001b[39m\u001b[33m  ╰── \u001b[39m\u001b[39m[Scalar - String], 5790 unique values\u001b[90m  # updated = 17763\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "chunks = Iterators.partition(train_indexes, div(train_size, THREADS))\n",
    "sch_parts = tmap(chunks) do ch\n",
    "    JsonGrinder.schema(jsons[ch])\n",
    "end\n",
    "time_split_complete_schema = merge(sch_parts...)\n",
    "printtree(time_split_complete_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31d48593-a53a-410c-baed-31ec2e799f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sch=schema(jsons);\n",
    "extractor=suggestextractor(time_split_complete_schema);\n",
    "data=map(extractor,jsons);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cbf71d1-8e03-4f92-b55e-31a35fadb0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.001, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelnames = sort(unique(df_labels.classification_family))\n",
    "neurons = 32\n",
    "model = reflectinmodel(time_split_complete_schema, extractor,\n",
    "\tk -> Dense(k, neurons, relu),\n",
    "\td -> SegmentedMeanMax(d),\n",
    "\tfsm = Dict(\"\" => k -> Dense(k, n_classes)),\n",
    ")\n",
    "\n",
    "minibatchsize = 50\n",
    "function minibatch()\n",
    "\tidx = StatsBase.sample(train_indexes, minibatchsize, replace = false)\n",
    "\treduce(catobs, data[idx]), Flux.onehotbatch(df_labels.classification_family[idx], labelnames)\n",
    "end\n",
    "\n",
    "iterations = 200\n",
    "\n",
    "function calculate_accuracy(x,y) \n",
    "    vals = tmap(x) do s\n",
    "        Flux.onecold(softmax(model(s)), labelnames)[1]\n",
    "    end\n",
    "    mean(vals .== y)\n",
    "end     \n",
    "    \n",
    "\n",
    "eval_trainset = shuffle(train_indexes)\n",
    "eval_testset = shuffle(test_indexes)\n",
    "\n",
    "cb = () -> begin\n",
    "\ttrain_acc = calculate_accuracy(data[eval_trainset], df_labels.classification_family[eval_trainset])\n",
    "\ttest_acc = calculate_accuracy(data[eval_testset], df_labels.classification_family[eval_testset])\n",
    "\tprintln(\"accuracy: train = $train_acc, test = $test_acc\")\n",
    "end\n",
    "ps = Flux.params(model)\n",
    "loss = (x,y) -> Flux.logitcrossentropy(model(x), y)\n",
    "opt = ADAM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a3820-9e29-4055-86be-7c5c51b89083",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "561747ba-b2de-42df-8b84-89273581aa00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "accuracy: train = 0.15299877600979192, test = 0.0273224043715847\n",
      "accuracy: train = 0.8837209302325582, test = 0.6229508196721312\n",
      "accuracy: train = 0.9167686658506732, test = 0.6994535519125683\n",
      "accuracy: train = 0.9290085679314566, test = 0.6830601092896175\n",
      "accuracy: train = 0.9461444308445532, test = 0.6830601092896175\n",
      "accuracy: train = 0.966952264381885, test = 0.7049180327868853\n",
      "accuracy: train = 0.981640146878825, test = 0.73224043715847\n",
      "accuracy: train = 0.97796817625459, test = 0.7486338797814208\n",
      "accuracy: train = 0.988984088127295, test = 0.7540983606557377\n",
      "accuracy: train = 0.9938800489596084, test = 0.7540983606557377\n",
      "accuracy: train = 0.9938800489596084, test = 0.7540983606557377\n",
      "accuracy: train = 0.9938800489596084, test = 0.7540983606557377\n",
      "accuracy: train = 0.9938800489596084, test = 0.7650273224043715\n",
      "accuracy: train = 0.996328029375765, test = 0.7650273224043715\n",
      "accuracy: train = 0.9951040391676866, test = 0.7650273224043715\n",
      "accuracy: train = 0.9951040391676866, test = 0.7704918032786885\n",
      "accuracy: train = 0.9987760097919217, test = 0.8579234972677595\n",
      "accuracy: train = 0.9987760097919217, test = 0.8306010928961749\n",
      "accuracy: train = 1.0, test = 0.7650273224043715\n",
      "accuracy: train = 0.9987760097919217, test = 0.7595628415300546\n",
      "accuracy: train = 0.9987760097919217, test = 0.7595628415300546\n",
      "accuracy: train = 0.9987760097919217, test = 0.7650273224043715\n",
      "Epoch 2\n",
      "accuracy: train = 0.9987760097919217, test = 0.7650273224043715\n",
      "accuracy: train = 0.9987760097919217, test = 0.7650273224043715\n",
      "accuracy: train = 0.9987760097919217, test = 0.7868852459016393\n",
      "accuracy: train = 0.9987760097919217, test = 0.9289617486338798\n",
      "accuracy: train = 0.9987760097919217, test = 0.8688524590163934\n",
      "accuracy: train = 0.9987760097919217, test = 0.8469945355191257\n",
      "accuracy: train = 0.9987760097919217, test = 0.8579234972677595\n",
      "accuracy: train = 0.9987760097919217, test = 0.8688524590163934\n",
      "accuracy: train = 1.0, test = 0.819672131147541\n",
      "accuracy: train = 1.0, test = 0.7868852459016393\n",
      "accuracy: train = 0.9987760097919217, test = 0.7759562841530054\n",
      "accuracy: train = 0.9987760097919217, test = 0.7704918032786885\n",
      "accuracy: train = 0.9987760097919217, test = 0.7704918032786885\n",
      "accuracy: train = 0.9987760097919217, test = 0.7704918032786885\n",
      "accuracy: train = 0.9987760097919217, test = 0.8579234972677595\n",
      "accuracy: train = 1.0, test = 0.9234972677595629\n",
      "accuracy: train = 1.0, test = 0.9234972677595629\n",
      "accuracy: train = 1.0, test = 0.912568306010929\n",
      "accuracy: train = 1.0, test = 0.8961748633879781\n",
      "accuracy: train = 1.0, test = 0.8306010928961749\n",
      "accuracy: train = 0.9987760097919217, test = 0.7923497267759563\n",
      "accuracy: train = 1.0, test = 0.8961748633879781\n",
      "Epoch 3\n",
      "accuracy: train = 1.0, test = 0.9289617486338798\n",
      "accuracy: train = 1.0, test = 0.9344262295081968\n",
      "accuracy: train = 1.0, test = 0.9344262295081968\n",
      "accuracy: train = 1.0, test = 0.9344262295081968\n",
      "accuracy: train = 1.0, test = 0.9234972677595629\n",
      "accuracy: train = 1.0, test = 0.9016393442622951\n",
      "accuracy: train = 1.0, test = 0.8688524590163934\n",
      "accuracy: train = 1.0, test = 0.8579234972677595\n",
      "accuracy: train = 1.0, test = 0.8907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n",
      "accuracy: train = 1.0, test = 0.907103825136612\n"
     ]
    }
   ],
   "source": [
    "epochs=3\n",
    "for i in 1:epochs\n",
    "    println(\"Epoch $(i)\")\n",
    "Flux.Optimise.train!(loss, ps, repeatedly(minibatch, iterations), opt, cb = Flux.throttle(cb, 2))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8486c-d85a-459c-8571-5fce97892899",
   "metadata": {},
   "source": [
    "# Accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a2a0a72-9a4b-46a0-80fa-166838c23824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation:\n",
      "Accuratcy on train data: 1.0\n",
      "Accuratcy on test data: 0.907103825136612\n"
     ]
    }
   ],
   "source": [
    "full_train_accuracy = calculate_accuracy(data[train_indexes], df_labels.classification_family[train_indexes])\n",
    "full_test_accuracy = calculate_accuracy(data[test_indexes], df_labels.classification_family[test_indexes])\n",
    "println(\"Final evaluation:\")\n",
    "println(\"Accuratcy on train data: $(full_train_accuracy)\")\n",
    "println(\"Accuratcy on test data: $(full_test_accuracy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0351be3f-b195-4108-99a5-e533790e88a9",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f128b0c-5e39-4bd1-8abb-42ab3ce142b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TL\\PL\t   Adload   Emotet   HarHar  Lokibot   Qakbot   Swisyn Trickbot   Ursnif     Zeus    njRAT\n",
      "  Adload\t   100.00     0.00     0.00     0.00     0.00     0.00     0.00     0.00     0.00     0.00\n",
      "  Emotet\t     7.14    85.71     0.00     0.00     0.00     0.00     3.57     0.00     3.57     0.00\n",
      "  HarHar\t     0.00     0.00   100.00     0.00     0.00     0.00     0.00     0.00     0.00     0.00\n",
      " Lokibot\t     0.00     0.00     0.00    88.89     0.00     0.00     0.00     0.00    11.11     0.00\n",
      "  Qakbot\t     0.00     0.00     0.00     0.00   100.00     0.00     0.00     0.00     0.00     0.00\n",
      "  Swisyn\t     0.00     0.00     0.00     2.78     0.00    97.22     0.00     0.00     0.00     0.00\n",
      "Trickbot\t     0.00     0.00     0.00     4.00     0.00     0.00    96.00     0.00     0.00     0.00\n",
      "  Ursnif\t     2.50     0.00     0.00     7.50     0.00     0.00     7.50    77.50     5.00     0.00\n",
      "    Zeus\t     0.00     0.00     0.00     0.00     0.00     0.00     0.00     0.00   100.00     0.00\n",
      "   njRAT\t     0.00     0.00     0.00     0.00     0.00     0.00     0.00     0.00     0.00   100.00\n"
     ]
    }
   ],
   "source": [
    "test_predictions = Dict()\n",
    "for true_label in labelnames\n",
    "    current_predictions = Dict()\n",
    "    [current_predictions[pl]=0.0 for pl in labelnames]\n",
    "    family_indexes = filter(i -> df_labels.classification_family[i] == true_label, test_indexes)\n",
    "    predictions = tmap(data[family_indexes]) do s\n",
    "        Flux.onecold(softmax(model(s)), labelnames)[1]\n",
    "    end\n",
    "    [current_predictions[pl] += 1.0 for pl in predictions]\n",
    "    [current_predictions[pl] = current_predictions[pl] ./ length(predictions) for pl in labelnames]\n",
    "    test_predictions[true_label] = current_predictions\n",
    "end\n",
    "\n",
    "@printf \"%8s\\t\" \"TL\\\\PL\"\n",
    "[@printf \" %8s\" s for s in labelnames]\n",
    "print(\"\\n\")\n",
    "for tl in labelnames\n",
    "    @printf \"%8s\\t\" tl \n",
    "    for pl in labelnames\n",
    "        @printf \"%9s\" @sprintf \"%.2f\" test_predictions[tl][pl]*100\n",
    "    end\n",
    "    print(\"\\n\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
